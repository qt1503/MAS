from typing import Literal, Optional, TypedDict
from langgraph.graph import StateGraph, START, END
from pydantic import BaseModel
from mint.PoT import ProgramOfThoughtsPrompt
from mint.chart import ChartGenerate, ExperimentDataFetcher
from mint.dataset_to_langsmith import DatasetToLangsmith
from mint.testing.test import TestingDataset
from langgraph.checkpoint.memory import MemorySaver
from langsmith import Client
from dotenv import load_dotenv

import argparse
import re
import sys
import uuid
import os
import io
import contextlib
import signal


class State(TypedDict):
    question: str
    answer: Optional[str]
    context: Optional[str]
    error: Optional[str]
    debug_count: int  
    show_reasoning: bool

class IntermediateProgram(BaseModel):
    program: str

def single_question(question: str, context: Optional[str] = None, show_reasoning: bool = False):
    
    prompt = ProgramOfThoughtsPrompt()

    builder = StateGraph(State)
    builder.add_node("PreProcessing", PreProcessing)
    builder.add_node("CodeGenerator", lambda state: CodeGenerator(state, prompt))
    builder.add_node("Verifier", lambda state: Verifier(state, prompt))
    builder.add_node("Executor", lambda state: Executor(state, prompt))
    builder.add_node("Debug_Feedback", lambda state: Debug_Feedback(state, prompt))
    builder.add_node("Answer", Answer)

    builder.add_edge(START, "PreProcessing")
    builder.add_edge("PreProcessing", "CodeGenerator")
    builder.add_edge("CodeGenerator", "Verifier")
    builder.add_conditional_edges("Verifier", decide_error)
    builder.add_conditional_edges("Executor", decide_executor)
    builder.add_edge("Debug_Feedback", "CodeGenerator")
    builder.add_edge("Answer", END)
    memory = MemorySaver()
    graph = builder.compile(checkpointer=memory)

    state = State(
        question=question,
        context=context,
        answer=None,
        error=None,
        debug_count=0,
        show_reasoning=show_reasoning
    )

    graph.invoke(
        input=state,
        config={"configurable": {"thread_id": str(uuid.uuid4())}}
    )


def PreProcessing(state: State):
    state["question"] = re.sub(r'\s+', ' ', state["question"].strip())                      
    print("Question: " + state["question"] + "\n")
    return {**state}

def CodeGenerator(state: State, prompt):
    generated_code = prompt.solve(state["question"], state["context"], state["show_reasoning"])
    return {**state, "debug_count": state.get('debug_count', 0), "answer": generated_code}

def Verifier(state: State, prompt):
    error = prompt.check_syntax_and_logic(state["answer"])
    return {**state, "debug_count": state.get('debug_count', 0), "error": error}

def Executor (state: State, prompt):
    result, success = prompt.safe_execute(str(state["answer"]))
    if success:
        return {**state, "debug_count": state.get('debug_count', 0), "answer": result}
    else:
        return {**state, "debug_count": state.get('debug_count', 0), "error": result}

def Debug_Feedback(state: State, prompt):
    fixed_code = prompt.fix_error(state["answer"], state["error"])
    return {**state, "debug_count": state.get('debug_count', 0) + 1, "error": None, "answer": fixed_code}

def Answer(state: State):
    answer = state.get("answer")
    if answer is not None:
        print("Answer: " + str(answer) + "\n")
    else:
        print("Answer: None\n")
    return {**state, "debug_count": state.get('debug_count', 0), "answer": answer}

def decide_error(state) -> Literal["Executor", "Debug_Feedback"]:
    error = state.get('error', None)
    debug_count = state.get('debug_count', 0)
    if debug_count >= 2:
        return "Executor"
    if error is None:
        return "Executor"
    return "Debug_Feedback"

def decide_executor(state) -> Literal["Answer", "Debug_Feedback"]:
    error = state.get('error', None)
    debug_count = state.get('debug_count', 0)
    if debug_count >= 2:
        return "Answer"
    if error is None:
        return "Answer"
    return "Debug_Feedback"


def check_dataset_exists(dataset_name: str) -> bool:
    """
    Kiá»ƒm tra xem dataset Ä‘Ã£ tá»“n táº¡i trÃªn LangSmith chÆ°a.
    
    Args:
        dataset_name (str): TÃªn dataset Ä‘á»ƒ kiá»ƒm tra
        
    Returns:
        bool: True náº¿u dataset tá»“n táº¡i, False náº¿u khÃ´ng
    """
    try:
        load_dotenv()
        client = Client()
        datasets = client.list_datasets()
        
        for dataset in datasets:
            if dataset.name.upper() == dataset_name.upper():
                return True
        return False
    except Exception as e:
        print(f"âš ï¸  KhÃ´ng thá»ƒ kiá»ƒm tra dataset trÃªn LangSmith: {e}")
        return False


def testing_dataset(method: str, dataset: str):
    """
    Kiá»ƒm tra dataset vá»›i phÆ°Æ¡ng phÃ¡p Ä‘Æ°á»£c chá»‰ Ä‘á»‹nh.
    TrÆ°á»›c tiÃªn sáº½ kiá»ƒm tra xem dataset Ä‘Ã£ Ä‘Æ°á»£c táº¡o trÃªn LangSmith chÆ°a.
    """
    # Danh sÃ¡ch cÃ¡c phÆ°Æ¡ng phÃ¡p vÃ  dataset cÃ³ sáºµn
    available_methods = ['Zero_shot', 'PoT', 'CoT', 'PaL', 'MultiAgent']
    available_datasets = ['GSM8K', 'TATQA', 'TABMWP']
    
    # XÃ¡c Ä‘á»‹nh danh sÃ¡ch dataset cáº§n kiá»ƒm tra
    datasets_to_test = []
    if dataset.lower() == 'all':
        datasets_to_test = available_datasets
    else:
        datasets_to_test = [dataset]
    
    # Kiá»ƒm tra xem cÃ¡c dataset Ä‘Ã£ tá»“n táº¡i trÃªn LangSmith chÆ°a
    for ds in datasets_to_test:
        if not check_dataset_exists(ds):
            print(f"âŒ Dataset {ds} chÆ°a Ä‘Æ°á»£c táº¡o trÃªn LangSmith!")
            print(f"ğŸ“ Vui lÃ²ng táº¡o dataset trÆ°á»›c báº±ng lá»‡nh:")
            print(f"   python mathqa.py create-dataset --dataset {ds}")
            print(f"   hoáº·c")
            print(f"   python mathqa.py create-dataset --dataset all --limit <sá»‘_lÆ°á»£ng>")
            return
    
    # XÃ¡c Ä‘á»‹nh danh sÃ¡ch phÆ°Æ¡ng phÃ¡p cáº§n kiá»ƒm tra
    methods_to_test = []
    if method.lower() == 'all':
        methods_to_test = available_methods
    else:
        methods_to_test = [method]
    
    print(f"âœ… Táº¥t cáº£ dataset Ä‘Ã£ sáºµn sÃ ng trÃªn LangSmith")
    print(f"ğŸš€ Báº¯t Ä‘áº§u kiá»ƒm tra...")
    print(f"ğŸ“Š PhÆ°Æ¡ng phÃ¡p: {', '.join(methods_to_test)}")
    print(f"ğŸ“š Dataset: {', '.join(datasets_to_test)}")
    print("-" * 60)
    
    # Cháº¡y kiá»ƒm tra cho táº¥t cáº£ cÃ¡c káº¿t há»£p method-dataset
    total_tests = len(methods_to_test) * len(datasets_to_test)
    current_test = 0
    
    for test_method in methods_to_test:
        for test_dataset in datasets_to_test:
            current_test += 1
            print(f"\nğŸ”„ Äang cháº¡y kiá»ƒm tra {current_test}/{total_tests}: {test_method} trÃªn {test_dataset}")
            print("=" * 50)
            
            try:
                test_case = TestingDataset(method=test_method, dataset=test_dataset)
                test_case.run()
                print(f"âœ… HoÃ n thÃ nh kiá»ƒm tra {test_method} trÃªn {test_dataset}")
            except Exception as e:
                print(f"âŒ Lá»—i khi cháº¡y {test_method} trÃªn {test_dataset}: {str(e)}")
            
            print("=" * 50)
    
    print(f"\nğŸ‰ ÄÃ£ hoÃ n thÃ nh táº¥t cáº£ {total_tests} kiá»ƒm tra!")
    print(f"ğŸ“ˆ Káº¿t quáº£ cÃ³ thá»ƒ xem trÃªn LangSmith dashboard.")


def create_dataset_to_langsmith(dataset: str, limit: int):
    """
    Táº¡o dataset trÃªn LangSmith vá»›i sá»‘ lÆ°á»£ng sample Ä‘Æ°á»£c chá»‰ Ä‘á»‹nh.
    
    Args:
        dataset (str): TÃªn dataset ('GSM8K', 'TATQA', 'TABMWP', hoáº·c 'all')
        limit (int): Sá»‘ lÆ°á»£ng sample Ä‘á»ƒ táº¡o
    """
    if dataset.upper() == "ALL":
        print(f"Äang táº¡o táº¥t cáº£ cÃ¡c dataset vá»›i {limit} samples...")
    else:
        print(f"Äang táº¡o dataset {dataset} vá»›i {limit} samples...")
    
    dataset_creator = DatasetToLangsmith(limit=limit)
    
    if dataset.upper() == "GSM8K":
        result = dataset_creator.create_gsm8k_dataset()
        print(f"âœ… ÄÃ£ táº¡o thÃ nh cÃ´ng dataset GSM8K vá»›i ID: {result.id}")
        
    elif dataset.upper() == "TATQA":
        result = dataset_creator.create_tatqa_dataset()
        print(f"âœ… ÄÃ£ táº¡o thÃ nh cÃ´ng dataset TATQA vá»›i ID: {result.id}")
        
    elif dataset.upper() == "TABMWP":
        result = dataset_creator.create_tabmwp_dataset()
        print(f"âœ… ÄÃ£ táº¡o thÃ nh cÃ´ng dataset TABMWP vá»›i ID: {result.id}")
        
    elif dataset.upper() == "ALL":
        results = dataset_creator.create_all_datasets()
        print("âœ… ÄÃ£ táº¡o thÃ nh cÃ´ng táº¥t cáº£ datasets:")
        for name, ds in results.items():
            print(f"  - {name.upper()}: {ds.id}")
    else:
        raise ValueError(f"Dataset khÃ´ng há»£p lá»‡: {dataset}. Sá»­ dá»¥ng 'GSM8K', 'TATQA', 'TABMWP', hoáº·c 'all'")
  
def main():
    parser = argparse.ArgumentParser(description="MathQA")
    print('-' * 50)
    subparsers = parser.add_subparsers(dest='command', title='Danh sÃ¡ch lá»‡nh Ä‘Æ°á»£c há»— trá»£', description="Chá»n má»™t trong cÃ¡c lá»‡nh bÃªn dÆ°á»›i Ä‘á»ƒ sá»­ dá»¥ng")

    # Single question
    single_parser = subparsers.add_parser('solve', help='Giáº£i quyáº¿t má»™t cÃ¢u há»i')
    single_parser.add_argument("--question", type=str, required=True, help="CÃ¢u há»i cáº§n giáº£i quyáº¿t")
    single_parser.add_argument("--context", help="Ngá»¯ cáº£nh tÃ¹y chá»n Ä‘á»ƒ sá»­ dá»¥ng", default="")
    single_parser.add_argument("--show-reasoning", action='store_true', help="Hiá»ƒn thá»‹ mÃ£ nguá»“n Ä‘Ã£ Ä‘Æ°á»£c sinh ra", default=False)

    # Dataset testing
    test_parser = subparsers.add_parser('test', help='Kiá»ƒm tra má»™t táº­p dá»¯ liá»‡u trÃªn LangSmith')
    test_parser.add_argument("--method", type=str, required=True, help="PhÆ°Æ¡ng thá»©c sá»­ dá»¥ng", choices=['Zero_shot', 'PoT', 'CoT', 'PaL', 'MultiAgent', 'all'])
    test_parser.add_argument("--dataset", type=str, required=True, help="Táº­p dá»¯ liá»‡u Ä‘á»ƒ kiá»ƒm tra", choices=['GSM8K', 'TATQA', 'TABMWP', 'all'])

    # Create dataset on LangSmith
    langsmith_parser = subparsers.add_parser('create-dataset', help='Táº¡o dataset trÃªn LangSmith')
    langsmith_parser.add_argument("--dataset", type=str, required=True, help="Táº­p dá»¯ liá»‡u Ä‘á»ƒ táº¡o", choices=['GSM8K', 'TATQA', 'TABMWP', 'all'])
    langsmith_parser.add_argument("--limit", type=int, default=300, help="Sá»‘ lÆ°á»£ng máº«u Ä‘á»ƒ táº¡o (máº·c Ä‘á»‹nh: 300)")

    # Show datasets
    list_parser = subparsers.add_parser('datasets', help='Hiá»ƒn thá»‹ danh sÃ¡ch cÃ¡c táº­p dá»¯ liá»‡u cÃ³ sáºµn')

    args = parser.parse_args()

    try:
        if args.command == 'solve':
            single_question(args.question, args.context, args.show_reasoning)

        elif args.command == 'test':
            testing_dataset(args.method, args.dataset)

        elif args.command == 'create-dataset':
            create_dataset_to_langsmith(args.dataset, args.limit)

        elif args.command == 'datasets':
            print("Available datasets:")
            print("-" * 50)
            print("GSM8K - bao gá»“m 8,500 bÃ i toÃ¡n toÃ¡n há»c cháº¥t lÆ°á»£ng cao cho há»c sinh tiá»ƒu há»c do cÃ¡c nhÃ  vÄƒn váº¥n Ä‘á» con ngÆ°á»i táº¡o ra.\n")
            print("TATQA - chá»©a 16,552 cÃ¢u há»i liÃªn quan Ä‘áº¿n 2,757 ngá»¯ cáº£nh káº¿t há»£p tá»« cÃ¡c bÃ¡o cÃ¡o tÃ i chÃ­nh thá»±c táº¿.\n")
            print("TABMWP - chá»©a 38,431 bÃ i toÃ¡n má»Ÿ cáº¥p Ä‘á»™ yÃªu cáº§u lÃ½ luáº­n toÃ¡n há»c trÃªn cáº£ dá»¯ liá»‡u vÄƒn báº£n vÃ  báº£ng.\n")

        elif args.command == 'chart':
            fetcher = ExperimentDataFetcher(args.experiment_id)
            fetcher.fetch_data()

            chart_generator = ChartGenerate(args.methods, args.datasets, args.metric)
            chart_generator.generate_chart()
        else:
            parser.print_help()

    except KeyboardInterrupt:
        print("\nNgÆ°á»i dÃ¹ng Ä‘Ã£ ngáº¯t quÃ¡ trÃ¬nh")
        sys.exit(1)
    except Exception as e:
        print(f"\nLá»—i: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()